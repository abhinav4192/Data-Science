{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "#from sklearn.model_selection import cross_validate\n",
    "\n",
    "folderPath = '../'\n",
    "trainArray = np.load(os.path.join(folderPath,'train.npy'))\n",
    "testArray = np.load(os.path.join(folderPath, 'test.npy'))\n",
    "\n",
    "trainData = trainArray[:,0:-1]\n",
    "trainLabel = trainArray[:,-1]\n",
    "\n",
    "testData = testArray[:,0:-1]\n",
    "testLabel = testArray[:,-1]\n",
    "\n",
    "## train split for debugging\n",
    "trainMetaDataFile = '../trainMetaData.txt'\n",
    "trainMetadata = []\n",
    "for line in open(trainMetaDataFile).readlines():\n",
    "    trainMetadata.append(line)\n",
    "\n",
    "testMetaDataFile = '../testMetaData.txt'\n",
    "testMetaData = []\n",
    "for line in open(testMetaDataFile).readlines():\n",
    "    testMetaData.append(line)\n",
    "\n",
    "#80-20 split\n",
    "nValSize = int(0.2*trainData.shape[0])\n",
    "nTrainSize =trainData.shape[0] - nValSize\n",
    "splitIdxs = random.sample(range(0,trainData.shape[0]), nValSize)\n",
    "\n",
    "valMetaMapping = { i : sidx for i,sidx in enumerate(splitIdxs) }\n",
    "\n",
    "nFeatures = 62\n",
    "nValData = np.zeros((nValSize,nFeatures))\n",
    "nValLabel = np.zeros((nValSize))\n",
    "\n",
    "nTrainData = np.zeros((nTrainSize,nFeatures))\n",
    "nTrainLabel = np.zeros((nTrainSize))\n",
    "\n",
    "tId = 0\n",
    "valId = 0\n",
    "valMetaData = []\n",
    "for idx in range(trainData.shape[0]):\n",
    "    if idx in splitIdxs:\n",
    "        nValData[valId,:] = trainData[idx,:]\n",
    "        nValLabel[valId] = trainLabel[idx]\n",
    "        valId += 1\n",
    "        valMetaData.append(trainMetadata[idx])\n",
    "    else:\n",
    "        nTrainData[tId, :] = trainData[idx,:]\n",
    "        nTrainLabel[tId] = trainLabel[idx]\n",
    "        tId += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validtion precision: [ 0.70042194  0.69273743  0.72673267  0.71713147  0.69102296]\n",
      "Decision Tree:\n",
      "\tPrecision = 0.704103671706\n",
      "\tRecall = 0.626923076923\n",
      "\tF1 = 0.663275686673\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier(min_samples_split=10, random_state=99)\n",
    "scores = cross_val_score(dt, trainData, trainLabel, scoring='precision', cv=5)\n",
    "\n",
    "#scoring = ['precision_macro', 'recall_macro']\n",
    "#scores = cross_validate(dt, trainData, trainLabel, scoring=scoring, cv=5, return_train_score=False)\n",
    "\n",
    "print ('5-fold cross validtion precision: ' + str(scores))\n",
    "\n",
    "dt = dt.fit(nTrainData, nTrainLabel)\n",
    "pred = dt.predict(nValData)\n",
    "prec = precision_score(nValLabel, pred)\n",
    "recall = recall_score(nValLabel, pred)\n",
    "f1Score = f1_score(nValLabel, pred)\n",
    "\n",
    "print ('Decision Tree:')\n",
    "print ('\\tPrecision = ' + str(prec))\n",
    "print ('\\tRecall = ' + str(recall))\n",
    "print ('\\tF1 = ' + str(f1Score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validtion precision: [ 0.93478261  0.92346939  0.92838196  0.91709845  0.90217391]\n",
      "Random Forest:\n",
      "\tPrecision = 0.921195652174\n",
      "\tRecall = 0.651923076923\n",
      "\tF1 = 0.763513513514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier(n_estimators=150, max_depth=50,  random_state=99)\n",
    "scores = cross_val_score(RF, trainData, trainLabel, scoring='precision', cv=5)\n",
    "print ('5-fold cross validtion precision: ' + str(scores))\n",
    "\n",
    "RF = RF.fit(nTrainData, nTrainLabel)\n",
    "pred = RF.predict(nValData)\n",
    "prec = precision_score(nValLabel, pred)\n",
    "recall = recall_score(nValLabel, pred)\n",
    "f1Score = f1_score(nValLabel, pred)\n",
    "\n",
    "print ('Random Forest:')\n",
    "print ('\\tPrecision = ' + str(prec))\n",
    "print ('\\tRecall = ' + str(recall))\n",
    "print ('\\tF1 = ' + str(f1Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine:\n",
      "\tPrecision = 0.695473251029\n",
      "\tRecall = 0.65\n",
      "\tF1 = 0.671968190855\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "bSVM = svm.SVC(class_weight='balanced')\n",
    "\n",
    "#scores = cross_val_score(bSVM, trainData, trainLabel, scoring='precision', cv=5)\n",
    "#print (scores)\n",
    "\n",
    "bSVM = bSVM.fit(nTrainData, nTrainLabel)\n",
    "pred = bSVM.predict(nValData)\n",
    "prec = precision_score(nValLabel, pred)\n",
    "recall = recall_score(nValLabel, pred)\n",
    "f1Score = f1_score(nValLabel, pred)\n",
    "\n",
    "print ('Support Vector Machine:')\n",
    "print ('\\tPrecision = ' + str(prec))\n",
    "print ('\\tRecall = ' + str(recall))\n",
    "print ('\\tF1 = ' + str(f1Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regerssion:\n",
      "\tPrecision = 0.8125\n",
      "\tRecall = 0.05\n",
      "\tF1 = 0.0942028985507\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "LR = LinearRegression()\n",
    "\n",
    "#scores = cross_val_score(LR, trainData, trainLabel, scoring='precision', cv=5)\n",
    "#print ('5-fold cross validtion precision: ' + str(scores))\n",
    "\n",
    "RF = LR.fit(nTrainData, nTrainLabel)\n",
    "pred = LR.predict(nValData)\n",
    "pred = np.where(pred > 0.5, 1, 0)\n",
    "prec = precision_score(nValLabel, pred)\n",
    "recall = recall_score(nValLabel, pred)\n",
    "f1Score = f1_score(nValLabel, pred)\n",
    "\n",
    "print ('Linear Regerssion:')\n",
    "print ('\\tPrecision = ' + str(prec))\n",
    "print ('\\tRecall = ' + str(recall))\n",
    "print ('\\tF1 = ' + str(f1Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validtion precision: [ 0.30867971  0.31425091  0.32356688  0.31657356  0.30656934]\n",
      "Logistic Regerssion:\n",
      "\tPrecision = 0.3025\n",
      "\tRecall = 0.930769230769\n",
      "\tF1 = 0.456603773585\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogR = LogisticRegression(random_state=99, class_weight='balanced', penalty='l1', C=10000)\n",
    "\n",
    "scores = cross_val_score(LogR, trainData, trainLabel, scoring='precision', cv=5)\n",
    "print ('5-fold cross validtion precision: ' + str(scores))\n",
    "\n",
    "LogR = LogR.fit(nTrainData, nTrainLabel)\n",
    "pred = LogR.predict(nValData)\n",
    "\n",
    "prec = precision_score(nValLabel, pred)\n",
    "recall = recall_score(nValLabel, pred)\n",
    "f1Score = f1_score(nValLabel, pred)\n",
    "\n",
    "print ('Logistic Regerssion:')\n",
    "print ('\\tPrecision = ' + str(prec))\n",
    "print ('\\tRecall = ' + str(recall))\n",
    "print ('\\tF1 = ' + str(f1Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest result on Test data (Set J):\n",
      "\tPrecision = 0.918590522479\n",
      "\tRecall = 0.621199671323\n",
      "\tF1 = 0.741176470588\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators=150, max_depth=50,  random_state=99)\n",
    "RF = RF.fit(trainData, trainLabel)\n",
    "pred = RF.predict(testData)\n",
    "\n",
    "prec = precision_score(testLabel, pred)\n",
    "recall = recall_score(testLabel, pred)\n",
    "f1Score = f1_score(testLabel, pred)\n",
    "\n",
    "print ('Random Forest result on Test data (Set J):')\n",
    "print ('\\tPrecision = ' + str(prec))\n",
    "print ('\\tRecall = ' + str(recall))\n",
    "print ('\\tF1 = ' + str(f1Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
