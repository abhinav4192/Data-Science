{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile, join\n",
    "import logging\n",
    "import re\n",
    "import commonUtils\n",
    "import constants\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCleanedWordListFromFile(fileName):\n",
    "    wordlist = []\n",
    "    fileText = open(fileName).read()\n",
    "    for line in fileText.splitlines():\n",
    "        for pattern in constants.nullReplaceList:\n",
    "            line = line.replace(pattern,'')\n",
    "        for pattern in constants.spaceReplaceList:\n",
    "            line = line.replace(pattern,' ')\n",
    "        for word in line.split(' '):\n",
    "            word = word.strip('\\'')\n",
    "            word = word.replace(\"[[[\",\"[[\")\n",
    "            word = word.replace(\"]]]\",\"]]\")\n",
    "            if(len(word)>=1):\n",
    "                wordlist.append(word)\n",
    "    return wordlist\n",
    "\n",
    "def getStringCombinationsFromWordList(wordlist):\n",
    "    allPossibeStringCombinations = []\n",
    "    for i in range(0,len(wordlist)):\n",
    "        currString = \"\"\n",
    "        for j in range(0,3):\n",
    "            if(i+j>=len(wordlist)):\n",
    "                break\n",
    "            if wordlist[i+j].lower() in [ig.lower() for ig in constants.wordsToIgnoreList]:\n",
    "                break\n",
    "            if any(char.isdigit() for char in wordlist[i+j]) :\n",
    "                break\n",
    "            if j > 0:\n",
    "                currString+=' '\n",
    "            currString+= wordlist[i+j]\n",
    "            if len(currString.strip(' ')) >=1:\n",
    "                allPossibeStringCombinations.append([currString.strip(' '),i,i+j])\n",
    "    return allPossibeStringCombinations\n",
    "\n",
    "\n",
    "def getPositivesAndNegatives(allPossibeStringCombinations):\n",
    "    positive = []\n",
    "    negative = []\n",
    "    for s,i,j in allPossibeStringCombinations:\n",
    "        if s.startswith('[[') and s.endswith(']]'):\n",
    "            if (\"[\" not in s[2:-2]) and (\"]\" not in s[2:-2]):\n",
    "                positive.append([s,i,j])\n",
    "            else:\n",
    "                negative.append([s,i,j])\n",
    "        else:\n",
    "            negative.append([s,i,j])\n",
    "    return positive,negative\n",
    "\n",
    "def getFeature1FirstWordCapital(token):\n",
    "    #[word, start, end]\n",
    "    # checks if first word of every word in token is capital\n",
    "    feature = 1\n",
    "    for word in token[0].split():\n",
    "        word = word.replace(\"[[\", '')\n",
    "        word = word.replace(\"]]\", '')\n",
    "        feature = feature & word[0].isupper()\n",
    "    return feature\n",
    "\n",
    "def getFeature2PreSuffixWordCapital(token, wordList):\n",
    "    #check if words either prev or after have capital letters\n",
    "    # flaky - \"Tom Cruise does\" - false positive for 'does'\n",
    "    # maybe helps to learn something\n",
    "    feature = 0\n",
    "    if token[1] > 0:\n",
    "        cmpWord = wordList[token[1] - 1].replace(\"[[\", '')\n",
    "        cmpWord = cmpWord.replace(\"]]\", '')\n",
    "        feature |= cmpWord[0].isupper()\n",
    "        \n",
    "    if token[2] < (len(wordList) - 1):\n",
    "        cmpWord = wordList[token[2] + 1].replace(\"[[\", '')\n",
    "        cmpWord = cmpWord.replace(\"]]\", '')\n",
    "        feature |= cmpWord[0].isupper()\n",
    "    return feature\n",
    "\n",
    "def getFeature3TokenLength(token):\n",
    "    return len(token[0].split())\n",
    "\n",
    "def getFeature4ProbPreSuff(token, wordList):\n",
    "    feature = 0\n",
    "    if token[1] > 0:\n",
    "        cmpWord = wordList[token[1] - 1].replace(\"[[\", '')\n",
    "        cmpWord = cmpWord.replace(\"]]\", '')\n",
    "        if cmpWord.lower() in [ig.lower() for ig in constants.positivePrefixSuffixList]:\n",
    "            feature |= 1\n",
    "    \n",
    "    if token[2] < (len(wordList) - 1):\n",
    "        cmpWord = wordList[token[2] + 1].replace(\"[[\", '')\n",
    "        cmpWord = cmpWord.replace(\"]]\", '')\n",
    "        if cmpWord.lower() in [ig.lower() for ig in constants.positivePrefixSuffixList]:\n",
    "            feature |= 1\n",
    "    return feature\n",
    "    \n",
    "#check if want to normalize it in some way\n",
    "def getFeature5TokenHash(token):\n",
    "    #http://cseweb.ucsd.edu/~kube/cls/100/Lectures/lec16/lec16-16.html\n",
    "    hashVal = 0\n",
    "    for char in token[0]:\n",
    "        hashVal = (hashVal << 4) + ord(char)\n",
    "        g = hashVal & 0xF0000000\n",
    "        if g != 0:\n",
    "            hashVal = hashVal ^ (g >> 24)\n",
    "        hashVal = hashVal & ~g\n",
    "    return hashVal\n",
    "\n",
    "def getFeature6OneHotVector(token):\n",
    "    #separate 26-26 for caps and lower case\n",
    "    charDictCaps = {chr(i) : 0 for i in range(65,91)}\n",
    "    charDictSmall = {chr(i) : 0 for i in range(97, 123)}\n",
    "    for char in token[0]:\n",
    "        if char in charDictCaps:\n",
    "            charDictCaps[char] += 1\n",
    "        elif char in charDictSmall:\n",
    "            charDictSmall[char] += 1\n",
    "    \n",
    "    charIdxCaps = {key : i for i,key in enumerate(charDictCaps.keys())}\n",
    "    charIdxSmall = {key : (i+26) for i,key in enumerate(charDictSmall.keys())}\n",
    "\n",
    "    OHvector = np.zeros((1,52))\n",
    "    for key in charDictCaps.keys():\n",
    "        OHvector[0,charIdxCaps[key]] = charDictCaps[key]\n",
    "    for key in charDictSmall.keys():\n",
    "        OHvector[0,charIdxSmall[key]] = charDictSmall[key]\n",
    "    \n",
    "    return OHvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3950 81967\n"
     ]
    }
   ],
   "source": [
    "folderNames = ['Abhinav','Bidyut','Chirayu']\n",
    "folderPath = '../dataset_markup/'\n",
    "totalMarkups = 0\n",
    "totalUniqueMarkups = set()\n",
    "p_total =0\n",
    "n_total = 0\n",
    "for fileName in commonUtils.getAllFiles(folderNames,folderPath):\n",
    "    wordList = getCleanedWordListFromFile(fileName)\n",
    "    l = getStringCombinationsFromWordList(wordList)\n",
    "    p,n = getPositivesAndNegatives(l)\n",
    "    p_total+=len(p)\n",
    "    n_total+=len(n)\n",
    "    \n",
    "print(p_total,n_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
